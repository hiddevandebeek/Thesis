@article{akaikeNewLookStatistical1974,
  title = {A New Look at the Statistical Model Identification},
  author = {Akaike, H.},
  year = {1974},
  month = dec,
  journal = {IEEE Transactions on Automatic Control},
  volume = {19},
  number = {6},
  pages = {716--723},
  issn = {1558-2523},
  doi = {10.1109/TAC.1974.1100705},
  urldate = {2023-11-16},
  abstract = {The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with some numerical examples.},
  file = {/Users/hiddevandebeek/Zotero/storage/UAU2CSFU/1100705.html}
}

@article{chowdhuryVariableSelectionStrategies2020,
  title = {Variable Selection Strategies and Its Importance in Clinical Prediction Modelling},
  author = {Chowdhury, Mohammad Ziaul Islam and Turin, Tanvir C},
  year = {2020},
  month = feb,
  journal = {Family Medicine and Community Health},
  volume = {8},
  number = {1},
  pages = {e000262},
  issn = {2305-6983},
  doi = {10.1136/fmch-2019-000262},
  urldate = {2023-11-16},
  abstract = {Clinical prediction models are used frequently in clinical practice to identify patients who are at risk of developing an adverse outcome so that preventive measures can be initiated. A prediction model can be developed in a number of ways; however, an appropriate variable selection strategy needs to be followed in all cases. Our purpose is to introduce readers to the concept of variable selection in prediction modelling, including the importance of variable selection and variable reduction strategies. We will discuss the various variable selection techniques that can be applied during prediction model building (backward elimination, forward selection, stepwise selection and all possible subset selection), and the stopping rule/selection criteria in variable selection (p values, Akaike information criterion, Bayesian information criterion and Mallows' Cp statistic). This paper focuses on the importance of including appropriate variables, following the proper steps, and adopting the proper methods when selecting variables for prediction models.},
  pmcid = {PMC7032893},
  pmid = {32148735},
  file = {/Users/hiddevandebeek/Zotero/storage/52CQFX4D/Chowdhury and Turin - 2020 - Variable selection strategies and its importance i.pdf}
}

@article{collinsTransparentReportingMultivariable2015,
  title = {Transparent {{Reporting}} of a {{Multivariable Prediction Model}} for {{Individual Prognosis}} or {{Diagnosis}} ({{TRIPOD}})},
  author = {Collins, Gary S. and Reitsma, Johannes B. and Altman, Douglas G. and Moons, Karel G.M.},
  year = {2015},
  month = jan,
  journal = {Circulation},
  volume = {131},
  number = {2},
  pages = {211--219},
  publisher = {American Heart Association},
  doi = {10.1161/CIRCULATIONAHA.114.014508},
  urldate = {2023-11-16},
  abstract = {Background--- Prediction models are developed to aid health care providers in estimating the probability or risk that a specific disease or condition is present (diagnostic models) or that a specific event will occur in the future (prognostic models), to inform their decision making. However, the overwhelming evidence shows that the quality of reporting of prediction model studies is poor. Only with full and clear reporting of information on all aspects of a prediction model can risk of bias and potential usefulness of prediction models be adequately assessed. Methods--- The Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) Initiative developed a set of recommendations for the reporting of studies developing, validating, or updating a prediction model, whether for diagnostic or prognostic purposes. This article describes how the TRIPOD Statement was developed. An extensive list of items based on a review of the literature was created, which was reduced after a Web-based survey and revised during a 3-day meeting in June 2011 with methodologists, health care professionals, and journal editors. The list was refined during several meetings of the steering group and in e-mail discussions with the wider group of TRIPOD contributors. Results--- The resulting TRIPOD Statement is a checklist of 22 items, deemed essential for transparent reporting of a prediction model study. The TRIPOD Statement aims to improve the transparency of the reporting of a prediction model study regardless of the study methods used. The TRIPOD Statement is best used in conjunction with the TRIPOD explanation and elaboration document. Conclusions--- To aid the editorial process and readers of prediction model studies, it is recommended that authors include a completed checklist in their submission (also available at www.tripod-statement.org).},
  keywords = {diagnosis,epidemiology,prognosis,research design,risk,statistics},
  file = {/Users/hiddevandebeek/Zotero/storage/RR6CMJJD/Collins et al. - 2015 - Transparent Reporting of a Multivariable Predictio.pdf}
}

@book{coxAnalysisBinaryData1989,
  title = {Analysis of {{Binary Data}}, {{Second Edition}}},
  author = {Cox, D. R. and Snell, E. J.},
  year = {1989},
  month = may,
  publisher = {CRC Press},
  abstract = {The first edition of this book (1970) set out a systematic basis for the analysis of binary data and in particular for the study of how the probability of 'success' depends on explanatory variables. The first edition has been widely used and the general level and style have been preserved in the second edition, which contains a substantial amount of new material. This amplifies matters dealt with only cryptically in the first edition and includes many more recent developments. In addition the whole material has been reorganized, in particular to put more emphasis on m.aximum likelihood methods.There are nearly 60 further results and exercises. The main points are illustrated by practical examples, many of them not in the first edition, and some general essential background material is set out in new Appendices.},
  googlebooks = {0R8J71LCLXsC},
  isbn = {978-0-412-30620-4},
  langid = {english},
  keywords = {Mathematics / Probability & Statistics / General}
}

@article{firthBiasReductionMaximum1993,
  title = {Bias Reduction of Maximum Likelihood Estimates},
  author = {Firth, D.},
  year = {1993},
  month = mar,
  journal = {Biometrika},
  volume = {80},
  number = {1},
  pages = {27--38},
  issn = {0006-3444},
  doi = {10.1093/biomet/80.1.27},
  urldate = {2024-05-10},
  abstract = {It is shown how, in regular parametric problems, the first-order term is removed from the asymptotic bias of maximum likelihood estimates by a suitable modification of the score function. In exponential families with canonical parameterization the effect is to penalize the likelihood by the Jeffreys invariant prior. In binomial logistic models, Poisson log linear models and certain other generalized linear models, the Jeffreys prior penalty function can be imposed in standard regression software using a scheme of iterative adjustments to the data.},
  file = {/Users/hiddevandebeek/Zotero/storage/SCM56CGN/228364.html}
}

@article{gartBiasVariousEstimators1967,
  title = {On the Bias of Various Estimators of the Logit and Its Variance with Application to Quantal Bioassay},
  author = {Gart, John J. and Zweifel, James R.},
  year = {1967},
  journal = {Biometrika},
  eprint = {2333861},
  eprinttype = {jstor},
  pages = {181--187},
  publisher = {JSTOR},
  urldate = {2024-05-10}
}

@book{harrellRegressionModelingStrategies2015,
  title = {Regression {{Modeling Strategies}}: {{With Applications}} to {{Linear Models}}, {{Logistic}} and {{Ordinal Regression}}, and {{Survival Analysis}}},
  shorttitle = {Regression {{Modeling Strategies}}},
  author = {Harrell, Frank E.},
  year = {2015},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-19425-7},
  urldate = {2023-11-16},
  isbn = {978-3-319-19424-0 978-3-319-19425-7},
  langid = {english},
  keywords = {Generalized least squares,knitr reproducible documents,Linear models,Logistic regression,Predictive modeling,R statistical software,Regression analysis,Survival analysis}
}

@article{kullbackInformationSufficiency1951,
  title = {On {{Information}} and {{Sufficiency}}},
  author = {Kullback, S. and Leibler, R. A.},
  year = {1951},
  journal = {The Annals of Mathematical Statistics},
  volume = {22},
  number = {1},
  eprint = {2236703},
  eprinttype = {jstor},
  pages = {79--86},
  publisher = {Institute of Mathematical Statistics},
  issn = {0003-4851},
  urldate = {2023-11-16},
  file = {/Users/hiddevandebeek/Zotero/storage/WV7VPTYM/Kullback and Leibler - 1951 - On Information and Sufficiency.pdf}
}

@article{ledellComputationallyEfficientConfidence2015,
  title = {Computationally Efficient Confidence Intervals for Cross-Validated Area under the {{ROC}} Curve Estimates},
  author = {LeDell, Erin and Petersen, Maya and {van der Laan}, Mark},
  year = {2015},
  journal = {Electronic journal of statistics},
  volume = {9},
  number = {1},
  pages = {1583--1607},
  issn = {1935-7524},
  doi = {10.1214/15-EJS1035},
  urldate = {2023-11-16},
  abstract = {In binary classification problems, the area under the ROC curve (AUC) is commonly used to evaluate the performance of a prediction model. Often, it is combined with cross-validation in order to assess how the results will generalize to an independent data set. In order to evaluate the quality of an estimate for cross-validated AUC, we obtain an estimate of its variance. For massive data sets, the process of generating a single performance estimate can be computationally expensive. Additionally, when using a complex prediction method, the process of cross-validating a predictive model on even a relatively small data set can still require a large amount of computation time. Thus, in many practical settings, the bootstrap is a computationally intractable approach to variance estimation. As an alternative to the bootstrap, we demonstrate a computationally efficient influence curve based approach to obtaining a variance estimate for cross-validated AUC.},
  pmcid = {PMC4533123},
  pmid = {26279737},
  file = {/Users/hiddevandebeek/Zotero/storage/Z82YAQSN/LeDell et al. - 2015 - Computationally efficient confidence intervals for.pdf}
}

@article{luijkenComparisonFullModel,
  title = {A Comparison of Full Model Specification and Backward Elimination of Potential Confounders When Estimating Marginal and Conditional Causal Effects on Binary Outcomes from Observational Data},
  author = {Luijken, Kim and Groenwold, Rolf H.H. and {van Smeden}, Maarten and Strohmaier, Susanne and Heinze, Georg},
  journal = {Biometrical Journal},
  volume = {n/a},
  number = {n/a},
  issn = {1521-4036},
  doi = {10.1002/bimj.202100237},
  urldate = {2023-11-28},
  abstract = {A common view in epidemiology is that automated confounder selection methods, such as backward elimination, should be avoided as they can lead to biased effect estimates and underestimation of their variance. Nevertheless, backward elimination remains regularly applied. We investigated if and under which conditions causal effect estimation in observational studies can improve by using backward elimination on a prespecified set of potential confounders. An expression was derived that quantifies how variable omission relates to bias and variance of effect estimators. Additionally, 3960 scenarios were defined and investigated by simulations comparing bias and mean squared error (MSE) of the conditional log odds ratio, log(cOR), and the marginal log risk ratio, log(mRR), between full models including all prespecified covariates and backward elimination of these covariates. Applying backward elimination resulted in a mean bias of 0.03 for log(cOR) and 0.02 for log(mRR), compared to 0.56 and 0.52 for log(cOR) and log(mRR), respectively, for a model without any covariate adjustment, and no bias for the full model. In less than 3\% of the scenarios considered, the MSE of the log(cOR) or log(mRR) was slightly lower (max 3\%) when backward elimination was used compared to the full model. When an initial set of potential confounders can be specified based on background knowledge, there is minimal added value of backward elimination. We advise not to use it and otherwise to provide ample arguments supporting its use.},
  copyright = {{\copyright} 2022 The Authors. Biometrical Journal published by Wiley-VCH GmbH.},
  langid = {english},
  keywords = {backward elimination,causal inference,confounder selection},
  file = {/Users/hiddevandebeek/Zotero/storage/HJ7RZ7PA/Luijken et al. - A comparison of full model specification and backw.pdf;/Users/hiddevandebeek/Zotero/storage/5WHJE5WY/bimj.html}
}

@article{mcfaddenConditionalLogitAnalysis1973,
  title = {Conditional Logit Analysis of Qualitative Choice Behavior},
  author = {McFadden, Daniel},
  year = {1973},
  publisher = {{Institute of Urban and Regional Development, University of California {\dots}}},
  urldate = {2023-11-16},
  file = {/Users/hiddevandebeek/Zotero/storage/QUHFFEX3/McFadden - 1973 - Conditional logit analysis of qualitative choice b.pdf}
}

@article{mittlbockNoteR2Measures2001,
  title = {A Note on {{R2}} Measures for {{Poisson}} and Logistic Regression Models When Both Models Are Applicable},
  author = {Mittlb{\"o}ck, Martina and Heinzl, Harald},
  year = {2001},
  month = jan,
  journal = {Journal of Clinical Epidemiology},
  volume = {54},
  number = {1},
  pages = {99--103},
  issn = {0895-4356},
  doi = {10.1016/S0895-4356(00)00292-4},
  urldate = {2023-11-16},
  abstract = {The aim of many epidemiological studies is the regression of a dichotomous outcome (e.g., death or affection by a certain disease) on prognostic covariables. Thereby the Poisson regression model is often used alternatively to the logistic regression model. Modelling the number of events and individual outcomes, respectively, both models lead to nearly the same results concerning the parameter estimates and their significances. However, when calculating the proportion of explained variation, quantified by an R2 measure, a large difference between both models usually occurs. We illustrate this difference by an example and explain it with theoretical arguments. We conclude, the R2 measure of the Poisson regression quantifies the predictability of event rates, but it is not adequate to quantify the predictability of the outcome of individual observations.},
  keywords = {Approximation,Deviance,Logistic regression,Poisson regression,R measure,Sums-of-squares},
  file = {/Users/hiddevandebeek/Zotero/storage/X9347T3I/S0895435600002924.html}
}

@article{moonsPrognosisPrognosticResearch2009,
  title = {Prognosis and Prognostic Research: Application and Impact of Prognostic Models in Clinical Practice},
  shorttitle = {Prognosis and Prognostic Research},
  author = {Moons, Karel G. M. and Altman, Douglas G. and Vergouwe, Yvonne and Royston, Patrick},
  year = {2009},
  month = jun,
  journal = {BMJ},
  volume = {338},
  pages = {b606},
  publisher = {British Medical Journal Publishing Group},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.b606},
  urldate = {2023-11-16},
  abstract = {{$<$}p{$>$}An accurate prognostic model is of no benefit if it is not generalisable or doesn't change behaviour. In the last article in their series \textbf{Karel Moons and colleagues }discuss how to determine the practical value of models {$<$}/p{$>$}},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {{\copyright} BMJ Publishing Group Ltd 2009},
  langid = {english},
  pmid = {19502216},
  file = {/Users/hiddevandebeek/Zotero/storage/BSF3B6BN/bmj.html}
}

@article{nagelkerkeNoteGeneralDefinition1991,
  title = {A Note on a General Definition of the Coefficient of Determination},
  author = {Nagelkerke, Nico JD},
  year = {1991},
  journal = {biometrika},
  volume = {78},
  number = {3},
  pages = {691--692},
  publisher = {Oxford University Press},
  urldate = {2023-11-16},
  file = {/Users/hiddevandebeek/Zotero/storage/7XEMVW95/Nagelkerke - 1991 - A note on a general definition of the coefficient .pdf}
}

@article{neathBayesianInformationCriterion2012,
  title = {The {{Bayesian}} Information Criterion: Background, Derivation, and Applications},
  shorttitle = {The {{Bayesian}} Information Criterion},
  author = {Neath, Andrew A. and Cavanaugh, Joseph E.},
  year = {2012},
  journal = {WIREs Computational Statistics},
  volume = {4},
  number = {2},
  pages = {199--203},
  issn = {1939-0068},
  doi = {10.1002/wics.199},
  urldate = {2023-11-16},
  abstract = {The Bayesian information criterion (BIC) is one of the most widely known and pervasively used tools in statistical model selection. Its popularity is derived from its computational simplicity and effective performance in many modeling frameworks, including Bayesian applications where prior distributions may be elusive. The criterion was derived by Schwarz (Ann Stat 1978, 6:461--464) to serve as an asymptotic approximation to a transformation of the Bayesian posterior probability of a candidate model. This article reviews the conceptual and theoretical foundations for BIC, and also discusses its properties and applications. WIREs Comput Stat 2012, 4:199--203. doi: 10.1002/wics.199 This article is categorized under: Statistical and Graphical Methods of Data Analysis {$>$} Bayesian Methods and Theory Statistical and Graphical Methods of Data Analysis {$>$} Information Theoretic Methods Statistical Learning and Exploratory Methods of the Data Sciences {$>$} Modeling Methods},
  copyright = {Copyright {\copyright} 2011 Wiley Periodicals, Inc.},
  langid = {english},
  keywords = {Bayes factors,BIC,model selection criterion,Schwarz information criterion},
  file = {/Users/hiddevandebeek/Zotero/storage/4PDLVXLC/wics.html}
}

@article{nemesBiasOddsRatios2009,
  title = {Bias in Odds Ratios by Logistic Regression Modelling and Sample Size},
  author = {Nemes, Szilard and Jonasson, Junmei Miao and Genell, Anna and Steineck, Gunnar},
  year = {2009},
  month = jul,
  journal = {BMC Medical Research Methodology},
  volume = {9},
  number = {1},
  pages = {56},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-9-56},
  urldate = {2024-05-10},
  abstract = {In epidemiological studies researchers use logistic regression as an analytical tool to study the association of a binary outcome to a set of possible exposures.},
  langid = {english},
  keywords = {Asymptotic Bias,Beta Coefficient,Estimate Regression Coefficient,Maximum Likelihood Estimator,Moderate Sample Size},
  file = {/Users/hiddevandebeek/Zotero/storage/4Q4KCNCR/Nemes et al. - 2009 - Bias in odds ratios by logistic regression modelli.pdf}
}

@article{pepeInterpretationROCCurve2000,
  title = {An {{Interpretation}} for the {{ROC Curve}} and {{Inference Using GLM Procedures}}},
  author = {Pepe, Margaret Sullivan},
  year = {2000},
  journal = {Biometrics},
  volume = {56},
  number = {2},
  pages = {352--359},
  issn = {1541-0420},
  doi = {10.1111/j.0006-341X.2000.00352.x},
  urldate = {2023-11-16},
  abstract = {Summary. The accuracy of a medical diagnostic test is often summarized in a receiver operating characteristic (ROC) curve. This paper puts forth an interpretation for each point on the ROC curve as being a conditional probability of a test result from a random diseased subject exceeding that from a random non diseased subject. This interpretation gives rise to new methods for making inference about ROC curves. It is shown that inference can be achieved with binary regression techniques applied to indicator variables constructed from pairs of test results, one component of the pair being from a diseased subject and the other from a non diseased subject. Within the generalized linear model (GLM) binary regression framework, ROC curves can be estimated, and we highlight a new semiparametric estimator. Covariate effects can also be evaluated with the GLM models. The methodology is applied to a pancreatic cancer dataset where we use the regression framework to compare two different serum biomarkers. Asymptotic distribution theory is developed to facilitate inference and to provide insight into factors influencing variability of estimated model parameters.},
  langid = {english},
  keywords = {Classification,Discriminant analysis,Disease screening,Medical diagnostic testing,Sensitivity,Specificity},
  file = {/Users/hiddevandebeek/Zotero/storage/WL8EP85W/j.0006-341X.2000.00352.html}
}

@techreport{rcoreteamLanguageEnvironmentStatistical2023b,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2023},
  address = {Vienna, Austria},
  institution = {R Foundation for Statistical Computing}
}

@article{ripleyPackageMass2013,
  title = {Package `Mass'},
  author = {Ripley, Brian and Venables, Bill and Bates, Douglas M. and Hornik, Kurt and Gebhardt, Albrecht and Firth, David and Ripley, Maintainer Brian},
  year = {2013},
  journal = {Cran r},
  volume = {538},
  pages = {113--120},
  urldate = {2024-05-09},
  file = {/Users/hiddevandebeek/Zotero/storage/3GBQIHGQ/Ripley et al. - 2013 - Package ‘mass’.pdf}
}

@article{robinPROCOpensourcePackage2011,
  title = {{{pROC}}: An Open-Source Package for {{R}} and {{S}}+ to Analyze and Compare {{ROC}} Curves},
  shorttitle = {{{pROC}}},
  author = {Robin, Xavier and Turck, Natacha and Hainard, Alexandre and Tiberti, Natalia and Lisacek, Fr{\'e}d{\'e}rique and Sanchez, Jean-Charles and M{\"u}ller, Markus},
  year = {2011},
  month = mar,
  journal = {BMC Bioinformatics},
  volume = {12},
  number = {1},
  pages = {77},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-12-77},
  urldate = {2023-11-28},
  abstract = {Receiver operating characteristic (ROC) curves are useful tools to evaluate classifiers in biomedical and bioinformatics applications. However, conclusions are often reached through inconsistent use or insufficient statistical analysis. To support researchers in their ROC curves analysis we developed pROC, a package for R and S+ that contains a set of tools displaying, analyzing, smoothing and comparing ROC curves in a user-friendly, object-oriented and flexible interface.},
  keywords = {Empirical Receiver Operating Characteristic Curve,Receiver Operating Characteristic,Receiver Operating Characteristic Analysis,Receiver Operating Characteristic Curve,Receiver Operating Characteristic Plot},
  file = {/Users/hiddevandebeek/Zotero/storage/7KXKIYP5/Robin et al. - 2011 - pROC an open-source package for R and S+ to analy.pdf;/Users/hiddevandebeek/Zotero/storage/KQ9CEKGL/1471-2105-12-77.html}
}

@misc{SampleSizeBinary,
  title = {Sample Size for Binary Logistic Prediction Models: {{Beyond}} Events per Variable Criteria - {{Maarten}} van {{Smeden}}, {{Karel GM Moons}}, {{Joris AH}} de {{Groot}}, {{Gary S Collins}}, {{Douglas G Altman}}, {{Marinus JC Eijkemans}}, {{Johannes B Reitsma}}, 2019},
  urldate = {2024-05-10},
  howpublished = {https://journals.sagepub.com/doi/full/10.1177/0962280218784726\#bibr24-0962280218784726},
  file = {/Users/hiddevandebeek/Zotero/storage/F2JUNPYY/0962280218784726.html}
}

@article{schwarzEstimatingDimensionModel1978,
  title = {Estimating the {{Dimension}} of a {{Model}}},
  author = {Schwarz, Gideon},
  year = {1978},
  journal = {The Annals of Statistics},
  volume = {6},
  number = {2},
  eprint = {2958889},
  eprinttype = {jstor},
  pages = {461--464},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  urldate = {2023-11-16},
  abstract = {The problem of selecting one of a number of models of different dimensions is treated by finding its Bayes solution, and evaluating the leading terms of its asymptotic expansion. These terms are a valid large-sample criterion beyond the Bayesian context, since they do not depend on the a priori distribution.},
  file = {/Users/hiddevandebeek/Zotero/storage/Y6HARYP2/Schwarz - 1978 - Estimating the Dimension of a Model.pdf}
}

@incollection{steyerbergApplicationsPredictionModels2009,
  title = {Applications of Prediction Models},
  booktitle = {Clinical {{Prediction Models}}: {{A Practical Approach}} to {{Development}}, {{Validation}}, and {{Updating}}},
  author = {Steyerberg, E.W.},
  editor = {Steyerberg, E.W.},
  year = {2009},
  series = {Statistics for {{Biology}} and {{Health}}},
  pages = {11--31},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-0-387-77244-8_2},
  urldate = {2023-11-16},
  isbn = {978-0-387-77244-8},
  langid = {english},
  keywords = {Breast Cancer,Deep Venous Thrombosis,Hereditary Breast Cancer,Propensity Score,Renal Artery Stenosis}
}

@article{steyerbergInternalExternalValidation2003,
  title = {Internal and External Validation of Predictive Models: {{A}} Simulation Study of Bias and Precision in Small Samples},
  shorttitle = {Internal and External Validation of Predictive Models},
  author = {Steyerberg, Ewout W and Bleeker, Sacha E and Moll, Henri{\"e}tte A and Grobbee, Diederick E and Moons, Karel G. M},
  year = {2003},
  month = may,
  journal = {Journal of Clinical Epidemiology},
  volume = {56},
  number = {5},
  pages = {441--447},
  issn = {0895-4356},
  doi = {10.1016/S0895-4356(03)00047-7},
  urldate = {2023-11-16},
  abstract = {We performed a simulation study to investigate the accuracy of bootstrap estimates of optimism (internal validation) and the precision of performance estimates in independent validation samples (external validation). We combined two data sets containing children presenting with fever without source (n=376+179=555; 120 bacterial infections). Random samples were drawn from this combined data set for the development (n=376) and validation (n=179) of logistic regression models. The models included statistically significant predictors for infection selected from a set of 57 candidate predictors. Model development, including the selection of predictors, and validation were repeated in a bootstrapping procedure. The resulting expected optimism estimate in the receiver operating characteristic (ROC) area was compared with the observed optimism according to independent validation samples. The average apparent ROC area was 0.74, which was expected (based on bootstrapping) to decrease by 0.07 to 0.67, whereas the observed decrease in the validation samples was 0.09 to 0.65. Omitting the selection of predictors from the bootstrap procedure led to a severe underestimation of the optimism (decrease 0.006). The standard error of the observed ROC area in the independent validation samples was large (0.05). We recommend bootstrapping for internal validation because it gives reasonably valid estimates of the expected optimism in predictive performance provided that any selection of predictors is taken into account. For external validation, substantial sample sizes should be used for sufficient power to detect clinically important changes in performance as compared with the internally validated estimate.},
  keywords = {Bootstrap,External validation,Internal validation,Logistic Regression,Prediction models},
  file = {/Users/hiddevandebeek/Zotero/storage/7824VSQ7/S0895435603000477.html}
}

@article{steyerbergInternalValidationPredictive2001,
  title = {Internal Validation of Predictive Models: {{Efficiency}} of Some Procedures for Logistic Regression Analysis},
  shorttitle = {Internal Validation of Predictive Models},
  author = {Steyerberg, Ewout W and Harrell, Frank E and Borsboom, Gerard J. J. M and Eijkemans, M. J. C and Vergouwe, Yvonne and Habbema, J. Dik F},
  year = {2001},
  month = aug,
  journal = {Journal of Clinical Epidemiology},
  volume = {54},
  number = {8},
  pages = {774--781},
  issn = {0895-4356},
  doi = {10.1016/S0895-4356(01)00341-9},
  urldate = {2023-11-28},
  abstract = {The performance of a predictive model is overestimated when simply determined on the sample of subjects that was used to construct the model. Several internal validation methods are available that aim to provide a more accurate estimate of model performance in new subjects. We evaluated several variants of split-sample, cross-validation and bootstrapping methods with a logistic regression model that included eight predictors for 30-day mortality after an acute myocardial infarction. Random samples with a size between n = 572 and n = 9165 were drawn from a large data set (GUSTO-I; n = 40,830; 2851 deaths) to reflect modeling in data sets with between 5 and 80 events per variable. Independent performance was determined on the remaining subjects. Performance measures included discriminative ability, calibration and overall accuracy. We found that split-sample analyses gave overly pessimistic estimates of performance, with large variability. Cross-validation on 10\% of the sample had low bias and low variability, but was not suitable for all performance measures. Internal validity could best be estimated with bootstrapping, which provided stable estimates with low bias. We conclude that split-sample validation is inefficient, and recommend bootstrapping for estimation of internal validity of a predictive logistic regression model.},
  keywords = {Bootstrapping,Internal validation,Logistic regression analysis,Predictive models},
  file = {/Users/hiddevandebeek/Zotero/storage/DIKNA2WN/S0895435601003419.html}
}

@article{tibshiraniRegressionShrinkageSelection1996,
  title = {Regression {{Shrinkage}} and {{Selection Via}} the {{Lasso}}},
  author = {Tibshirani, Robert},
  year = {1996},
  month = jan,
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {58},
  number = {1},
  pages = {267--288},
  issn = {0035-9246},
  doi = {10.1111/j.2517-6161.1996.tb02080.x},
  urldate = {2024-05-10},
  abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
  file = {/Users/hiddevandebeek/Zotero/storage/25LRRDHU/Tibshirani - 1996 - Regression Shrinkage and Selection Via the Lasso.pdf;/Users/hiddevandebeek/Zotero/storage/H3VX2U2I/7027929.html}
}

@article{vansmedenNoRationaleVariable2016,
  title = {No Rationale for 1 Variable per 10 Events Criterion for Binary Logistic Regression Analysis},
  author = {{van Smeden}, Maarten and {de Groot}, Joris A. H. and Moons, Karel G. M. and Collins, Gary S. and Altman, Douglas G. and Eijkemans, Marinus J. C. and Reitsma, Johannes B.},
  year = {2016},
  month = nov,
  journal = {BMC Medical Research Methodology},
  volume = {16},
  number = {1},
  pages = {163},
  issn = {1471-2288},
  doi = {10.1186/s12874-016-0267-3},
  urldate = {2023-12-18},
  abstract = {Ten events per variable (EPV) is a widely advocated minimal criterion for sample size considerations in logistic regression analysis. Of three previous simulation studies that examined this minimal EPV criterion only one supports the use of a minimum of 10 EPV. In this paper, we examine the reasons for substantial differences between these extensive simulation studies.},
  langid = {english},
  keywords = {Bias,EPV,Logistic regression,Sample size,Separation,Simulations},
  file = {/Users/hiddevandebeek/Zotero/storage/TLEVEHBK/van Smeden et al. - 2016 - No rationale for 1 variable per 10 events criterio.pdf}
}

@article{vansmedenSampleSizeBinary2019,
  title = {Sample Size for Binary Logistic Prediction Models: {{Beyond}} Events per Variable Criteria},
  shorttitle = {Sample Size for Binary Logistic Prediction Models},
  author = {{van Smeden}, Maarten and Moons, Karel GM and {de Groot}, Joris AH and Collins, Gary S and Altman, Douglas G and Eijkemans, Marinus JC and Reitsma, Johannes B},
  year = {2019},
  month = aug,
  journal = {Statistical Methods in Medical Research},
  volume = {28},
  number = {8},
  pages = {2455--2474},
  publisher = {SAGE Publications Ltd STM},
  issn = {0962-2802},
  doi = {10.1177/0962280218784726},
  urldate = {2024-05-10},
  abstract = {Binary logistic regression is one of the most frequently applied statistical approaches for developing clinical prediction models. Developers of such models often rely on an Events Per Variable criterion (EPV), notably EPV {$\geq$}10, to determine the minimal sample size required and the maximum number of candidate predictors that can be examined. We present an extensive simulation study in which we studied the influence of EPV, events fraction, number of candidate predictors, the correlations and distributions of candidate predictor variables, area under the ROC curve, and predictor effects on out-of-sample predictive performance of prediction models. The out-of-sample performance (calibration, discrimination and probability prediction error) of developed prediction models was studied before and after regression shrinkage and variable selection. The results indicate that EPV does not have a strong relation with metrics of predictive performance, and is not an appropriate criterion for (binary) prediction model development studies. We show that out-of-sample predictive performance can better be approximated by considering the number of predictors, the total sample size and the events fraction. We propose that the development of new sample size criteria for prediction models should be based on these three parameters, and provide suggestions for improving sample size determination.},
  langid = {english},
  file = {/Users/hiddevandebeek/Zotero/storage/NFQEYS4Q/van Smeden et al. - 2019 - Sample size for binary logistic prediction models.pdf}
}

@article{wesslerTuftsPACEClinical2017,
  title = {Tufts {{PACE Clinical Predictive Model Registry}}: Update 1990 through 2015},
  shorttitle = {Tufts {{PACE Clinical Predictive Model Registry}}},
  author = {Wessler, Benjamin S. and Paulus, Jessica and Lundquist, Christine M. and Ajlan, Muhammad and Natto, Zuhair and Janes, William A. and Jethmalani, Nitin and Raman, Gowri and Lutz, Jennifer S. and Kent, David M.},
  year = {2017},
  month = dec,
  journal = {Diagnostic and Prognostic Research},
  volume = {1},
  number = {1},
  pages = {20},
  issn = {2397-7523},
  doi = {10.1186/s41512-017-0021-2},
  urldate = {2023-11-16},
  abstract = {Clinical predictive models (CPMs) estimate the probability of clinical outcomes and hold the potential to improve decision-making and individualize care. The Tufts Predictive Analytics and Comparative Effectiveness (PACE) CPM Registry is a comprehensive database of cardiovascular disease (CVD) CPMs. The Registry was last updated in 2012, and there continues to be substantial growth in the number of available CPMs.},
  langid = {english},
  keywords = {Cardiovascular disease risk factors,Cerebrovascular disease/stroke,Clinical predictive model,Coronary artery disease,Methods,Modeling,Prediction,Prognostic factor,Risk stratification},
  file = {/Users/hiddevandebeek/Zotero/storage/CMZBLZGN/Wessler et al. - 2017 - Tufts PACE Clinical Predictive Model Registry upd.pdf}
}

@incollection{wickhamGettingStartedGgplot22016,
  title = {Getting {{Started}} with Ggplot2},
  booktitle = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  author = {Wickham, Hadley},
  editor = {Wickham, Hadley},
  year = {2016},
  series = {Use {{R}}!},
  pages = {11--31},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-24277-4_2},
  urldate = {2023-12-03},
  abstract = {The goal of this chapter is to teach you how to produce useful graphics with ggplot2 as quickly as possible. You'll learn the basics of ggplot() along with some useful ``recipes'' to make the most important plots. ggplot() allows you to make complex plots with just a few lines of code because it's based on a rich underlying theory, the grammar of graphics. Here we'll skip the theory and focus on the practice, and in later chapters you'll learn how to use the full expressive power of the grammar.},
  isbn = {978-3-319-24277-4},
  langid = {english},
  keywords = {Fuel Economy,Full Expressive Power,Function Geom,Path Plots,Plot Object}
}

@article{zhouRelationshipIncrementalValues2021,
  title = {A Relationship between the Incremental Values of Area under the {{ROC}} Curve and of Area under the Precision-Recall Curve},
  author = {Zhou, Qian M. and Zhe, Lu and Brooke, Russell J. and Hudson, Melissa M. and Yuan, Yan},
  year = {2021},
  month = jul,
  journal = {Diagnostic and Prognostic Research},
  volume = {5},
  number = {1},
  pages = {13},
  issn = {2397-7523},
  doi = {10.1186/s41512-021-00102-w},
  urldate = {2023-11-16},
  abstract = {Incremental value (IncV) evaluates the performance change between an existing risk model and a new model. Different IncV metrics do not always agree with each other. For example, compared with a prescribed-dose model, an ovarian-dose model for predicting acute ovarian failure has a slightly lower area under the receiver operating characteristic curve (AUC) but increases the area under the precision-recall curve (AP) by 48\%. This phenomenon of disagreement is not uncommon, and can create confusion when assessing whether the added information improves the model prediction accuracy.},
  keywords = {Area under precision-recall curve,AUC,Brier score,Prediction performance,Proper scoring rules,Rare outcome},
  file = {/Users/hiddevandebeek/Zotero/storage/CFJRFB7X/Zhou et al. - 2021 - A relationship between the incremental values of a.pdf;/Users/hiddevandebeek/Zotero/storage/T3J324VP/s41512-021-00102-w.html}
}
