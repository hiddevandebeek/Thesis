---
title: "Visualization Report"
author: "Hidde van de Beek"
date: "2023-11-20"
output: html_document
---

## Libraries
```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(caTools)
library(plotly)
library(MASS)
library(matlib)
library(dplyr)
library(pROC)
library(parallel)
library(CalibrationCurves)
```


## Open data
```{r}
data <- read_rds("/Users/hiddevandebeek/Documents/Documents - Hiddeâ€™s MacBook Pro/Github/Thesis/data/data_report.rds")
```


## Sampling function for imbalanced data
```{r}
sample_data <- function(data, size, perc_ones, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  
  # Separate data into two subsets based on y
  data_0 <- filter(data, y == 0)
  data_1 <- filter(data, y == 1)
  
  # Calculate the number of samples required from each subset
  num_ones <- round(size * perc_ones)
  num_zeros <- size - num_ones
  
  # Sample from each subset
  sampled_0 <- sample_n(data_0, min(num_zeros, nrow(data_0)))
  sampled_1 <- sample_n(data_1, min(num_ones, nrow(data_1)))
  
  # Combine the sampled subsets
  sampled_data <- rbind(sampled_0, sampled_1)
  
  # Shuffle the rows
  sampled_data <- sampled_data[sample(nrow(sampled_data)), ]
  
  return(sampled_data)
}
```


## Plotting ROC curves
### Function to plot ROC curves
```{r, warning=FALSE, message=FALSE}
fit_and_evaluate <- function(original_data, times, sample_size, perc_ones, test_size = 0.2, seed = NULL) {
  if (!is.null(seed)) set.seed(seed)
  
  auc_values <- numeric(times)  # Vector to store AUC values
  roc_curves <- data.frame()    # Data frame to store ROC curves points
  
  for (i in 1:times) {
    # Sample from the original dataset
    data <- sample_data(original_data, size = sample_size, perc_ones = perc_ones, seed = seed)
    
    # Split the data
    index <- sample(1:nrow(data), size = round(nrow(data) * test_size))
    test_set <- data[index, ]
    train_set <- data[-index, ]
    
    # Fit logistic regression model
    full_model <- glm(y ~ (.)^2, data = train_set, family = "binomial")
    step_model <- stepAIC(full_model, direction = "both", trace = FALSE)
    
    # Predict on test set
    predictions <- predict(step_model, newdata = test_set, type = "response")
    
    # Evaluate model performance using AUC
    roc_obj <- suppressMessages(roc(response = test_set$y, predictor = predictions, quiet = TRUE))
    auc_values[i] <- auc(roc_obj)
    
    # Store ROC curve points
    roc_curves <- rbind(roc_curves, data.frame(
      tpr = roc_obj$sensitivities,
      fpr = 1 - roc_obj$specificities,
      iteration = i
    ))
  }
  
  # Calculate the average AUC
  mean_auc <- mean(auc_values)
  
  # Plot all ROC curves
  roc_plot <- ggplot(roc_curves, aes(x = fpr, y = tpr, group = iteration, color = as.factor(iteration))) +
              geom_line(alpha = 0.3) +
              geom_line(data = data.frame(fpr = c(0, 1), tpr = c(0, 1)),
                        aes(x = fpr, y = tpr), linetype = "dashed", inherit.aes = FALSE) +
              theme_minimal() +
              labs(color = "Iteration") +
              ggtitle("ROC Curves from Multiple Iterations")
  
  return(list(AverageAUC = mean_auc, ROCPlot = roc_plot))
}
```
### Function with different sample sizes and 50% of ones
```{r, warning=FALSE, message=FALSE}
# Example usage
results.5.100 <- fit_and_evaluate(data, times = 40, sample_size = 100, test_size = .8, perc_ones = 0.5)
results.5.200 <- fit_and_evaluate(data, times = 40, sample_size = 200, test_size = .8, perc_ones = 0.5)
results.5.400 <- fit_and_evaluate(data, times = 40, sample_size = 400, test_size = .8, perc_ones = 0.5)

# Print average AUC
print(results.5.100$AverageAUC)
print(results.5.200$AverageAUC)
print(results.5.400$AverageAUC)

# Plot ROC curves
print(results.5.100$ROCPlot)
print(results.5.200$ROCPlot)
print(results.5.400$ROCPlot)
```

### Function with different sample sizes and 20% of ones
```{r, warning=FALSE, message=FALSE}
# Example usage
results.20.100 <- fit_and_evaluate(data, times = 40, sample_size = 100, test_size = .8, perc_ones = 0.2)
results.20.200 <- fit_and_evaluate(data, times = 40, sample_size = 200, test_size = .8, perc_ones = 0.2)
results.20.400 <- fit_and_evaluate(data, times = 40, sample_size = 400, test_size = .8, perc_ones = 0.2)

# Print average AUC
print(results.20.100$AverageAUC)
print(results.20.200$AverageAUC)
print(results.20.400$AverageAUC)

# Plot ROC curves
print(results.20.100$ROCPlot)
print(results.20.200$ROCPlot)
print(results.20.400$ROCPlot)
```

### Function with different sample sizes and 5% of ones
```{r, warning=FALSE, message=FALSE}
# Example usage
results.05.100 <- fit_and_evaluate(data, times = 40, sample_size = 400, test_size = .6, perc_ones = 0.05)
results.05.200 <- fit_and_evaluate(data, times = 40, sample_size = 800, test_size = .6, perc_ones = 0.05)
results.05.400 <- fit_and_evaluate(data, times = 40, sample_size = 1600, test_size = .6, perc_ones = 0.05)

# Print average AUC
print(results.05.100$AverageAUC)
print(results.05.200$AverageAUC)
print(results.05.400$AverageAUC)

# Plot ROC curves
print(results.05.100$ROCPlot)
print(results.05.200$ROCPlot)
print(results.05.400$ROCPlot)

```

### Example of calibration plot
```{r}
experiment.data <-sample_data(data, 1000, 0.5, seed = 28)
test_set <- experiment.data[1:500, ]
train_set <- experiment.data[501:1000, ]

full_model <- glm(y ~ (.)^2, data = train_set, family = "binomial")
step_model <- stepAIC(full_model, direction = "both", trace = FALSE)

pHat = predict(step_model, newdata = test_set, type = "response")
yTest = test_set$y

invisible(val.prob.ci.2(pHat, yTest, logistic.cal = TRUE, smooth = "none"))
```





## Experiment 1: Percentage of selecting the correct model
```{r}
```

## Experiment 2: Percentage of selecting the best performing validated model
```{r}

```

