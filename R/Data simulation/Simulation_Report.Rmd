---
title: "Simulation Test Thesis"
output: html_document
date: "2023-10-27"
---

---
title: "Simulation Test"
output: html_document
date: "2023-10-25"
---

## Setup
### Libraries
```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(caTools)
library(plotly)
library(MASS)
library(matlib)
library(dplyr)
library(pROC)
library(parallel)
library(CalibrationCurves)
```
### Initialize variables
```{r}
# Set random seed for reproducibility
set.seed(28)
p      <- 1                               # proportion of correlated predictors
npred  <- 3                               # number of predictors
z      <- 0.2                             # z 
n      <- 2000000                         # Number of samples in the dataset
a <- 4                               # the effect size
```
### Calculate sigma
```{r}
scenario <- function(){
  # set up correlations
  corr0  <-  matrix(0, npred, npred)         # matrix: set up for cov matrix, 0 on diagonals
  corr0[1:npred*p, 1:npred*p] = z            # class 0 
  diag(corr0) = 0
  # covariance structures
  sigma0 <-  diag(npred)  + corr0            # matrix: cov matrix of class 0 
  return(sigma0)
}
```


## Simulate data
Simulate data for diseased class and non-diseased class using a covariance matrix and mean vector using the MASS package. The covariance matrix is chosen such that the two predictors are correlated. The mean vector is chosen such that the diseased class has a higher mean than the non-diseased class for both predictors. The data is then combined into a single dataset.
```{r, cache=T}
# mean structures
mu0 <- c(rep(1,npred))       # vector: class 0 means

# covariance structures
sigma0 <- scenario()         # class 0

# Generate data for non-diseased class
system.time(
data <- mvrnorm(n, mu = mu0, Sigma = sigma0) %>%
  as.data.frame())

# Rename columns to "predictor1", "predictor2" ,...
colnames(data) <- c(paste0("predictor", 1:(ncol(data))))

# Simulate binary y to have Prob(y=1) = 1/[1+exp(-L)]
L <-  0.2*a*data$predictor1 + 0.2*a*data$predictor2 + 0.1*a*data$predictor3
mean(L)
L <- - mean(L) + 0.2*a*data$predictor1 + 0.2*a*data$predictor2 + 0.1*a*data$predictor3 # 50/50 split

y <- ifelse(runif(n) < plogis(L), 1, 0)
data <- cbind(data, y)

#proportion y's in data
prop.table(table(data$y))
```

## Plot distributions for Predictors
### 2D Histograms
```{r, cache=TRUE}
# Plot for Predictor 1
ggplot(data, aes(x = predictor1, fill = as.factor(y))) +
  geom_histogram(alpha = 0.5, position = 'identity', bins = 200) +
  ggtitle("Distribution of Diseased and Non-Diseased Classes for Predictor 1")

# Plot for Predictor 2
ggplot(data, aes(x = predictor2, fill = as.factor(y))) +
  geom_histogram(alpha = 0.5, position = 'identity', bins = 200) +
  ggtitle("Distribution of Diseased and Non-Diseased Classes for Predictor 2")

# Plot for Predictor 3
ggplot(data, aes(x = predictor3, fill = as.factor(y))) +
  geom_histogram(alpha = 0.5, position = 'identity', bins = 200) +
  ggtitle("Distribution of Diseased and Non-Diseased Classes for Predictor 3")
```

### 3D Histogram of Predictor 1 and Predictor 2
```{r, warning=FALSE, cache=TRUE}
# Calculate densities for class 1 and class 0
density1 <- with(data[data$y == 1, ], kde2d(predictor1, predictor2, n = 30))
density0 <- with(data[data$y == 0, ], kde2d(predictor1, predictor2, n = 30))

# Create the interactive 3D plot
p1 <- plot_ly(z = ~density1$z) %>% 
  add_surface(
    x = ~density1$x,
    y = ~density1$y,
    colorscale = list(c(0, "red"), list(1, "pink")),
    opacity = 0.8
  )

p2 <- plot_ly(z = ~density0$z) %>% 
  add_surface(
    x = ~density0$x,
    y = ~density0$y,
    colorscale = list(c(0, "blue"), list(1, "lightblue")),
    opacity = 0.8
  )

plot <- plotly::subplot(p1, p2, nrows = 1, shareX = TRUE, shareY = TRUE)
plot
```

## Logistic Regression and checking AUC for linear separability
```{r, cache=TRUE}
numCores <- detectCores()
numCores

n_iter <- 200
sample_ratio <- 0.15

# Create a cluster with the desired number of cores (e.g., 4)
cl <- makeCluster(numCores-1)
on.exit(stopCluster(cl))
clusterExport(cl, varlist = c("data", "sample_ratio"))
clusterEvalQ(cl,expr= { # launch library to be used in FUN
  library(caTools)
})

# Define the function to run in each iteration
run_iteration <- function(i, data, sample_ratio) {
  sample_index <- sample(1:nrow(data), sample_ratio * nrow(data))
  sample_data <- data[sample_index, ]
  
  model <- glm(y ~ ., data = sample_data, family = binomial)
  predictions <- predict(model, newdata = sample_data, type = "response")

  # Assuming 'colAUC' is available or replaced with an equivalent function
  auc <- colAUC(predictions, sample_data$y, plotROC = FALSE)

  list(auc = auc, coefficients = model$coefficients)
}

# Run the iterations in parallel
system.time(results <- parLapply(cl, 1:n_iter, run_iteration, data, sample_ratio))

# Extract AUC values and coefficients
auc_values <- sapply(results, function(x) x$auc)
coefficients <- Reduce("+", lapply(results, function(x) x$coefficients))

# Calculate average AUC and coefficients
average_auc <- mean(auc_values)
average_coefficients <- coefficients / n_iter

print(paste("Average AUC: ", round(average_auc, 4)))
print(paste("Average coefficients: ", round(average_coefficients, 2)))
```

# Save Data in RDS Format in data folder
```{r}
saveRDS(data, "/Users/hiddevandebeek/Documents/Documents - Hiddeâ€™s MacBook Pro/Github/Thesis/data/data_report.rds")
```

